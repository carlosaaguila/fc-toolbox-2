{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "662e3d5a-e8ad-4199-bc34-a670a4316793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ieeg-portal/ieegpy.git\n",
      "  Cloning https://github.com/ieeg-portal/ieegpy.git to /private/var/folders/j3/ps9_bddj0kg0ds3px8t769_00000gn/T/pip-req-build-bt5bzhiv\n",
      "  Running command git clone -q https://github.com/ieeg-portal/ieegpy.git /private/var/folders/j3/ps9_bddj0kg0ds3px8t769_00000gn/T/pip-req-build-bt5bzhiv\n",
      "  Resolved https://github.com/ieeg-portal/ieegpy.git to commit 080bfa42a8503380ef164b5e7b116613f75073bb\n",
      "Requirement already satisfied: deprecation in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from ieeg==1.6) (2.1.0)\n",
      "Requirement already satisfied: requests in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from ieeg==1.6) (2.26.0)\n",
      "Requirement already satisfied: numpy in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from ieeg==1.6) (1.20.3)\n",
      "Requirement already satisfied: pandas in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from ieeg==1.6) (1.3.4)\n",
      "Requirement already satisfied: pennprov==2.2.4 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from ieeg==1.6) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from pennprov==2.2.4->ieeg==1.6) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from pennprov==2.2.4->ieeg==1.6) (2021.10.8)\n",
      "Requirement already satisfied: urllib3>=1.23 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from pennprov==2.2.4->ieeg==1.6) (1.26.7)\n",
      "Requirement already satisfied: six>=1.10 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from pennprov==2.2.4->ieeg==1.6) (1.16.0)\n",
      "Requirement already satisfied: packaging in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from deprecation->ieeg==1.6) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from packaging->deprecation->ieeg==1.6) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from pandas->ieeg==1.6) (2021.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from requests->ieeg==1.6) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/carlosaguila/opt/anaconda3/lib/python3.9/site-packages (from requests->ieeg==1.6) (3.2)\n"
     ]
    }
   ],
   "source": [
    "#establishing environment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "from scipy.io import loadmat, savemat\n",
    "!pip install git+https://github.com/ieeg-portal/ieegpy.git # Install ieegpy toolbox directly from github\n",
    "from ieeg.auth import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "635039ce-a190-4680-ae1a-5c5f8e877be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_HUP203 = loadmat('/Users/carlosaguila/PycharmProjects/CNT_Interictal_Spikes/Results_v1/split_HUP203_phaseII.mat'); #local machine save #this is 10 gdfs\n",
    "#new mat file is trimmed down amount of values. drop many of the channels and only imported the 0.5s's before and after a spike for every spike in every sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c533305-c7e2-4826-8057-fb2a6fab073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the binary file and use its content to create a session frmo IEEG\n",
    "with open('/Users/carlosaguila/Documents/BE521/agu_ieeglogin.bin', 'r') as f:\n",
    "    session = Session('aguilac', f.read())\n",
    "#get the specified dataset from IEEG\n",
    "dataset = session.open_dataset('HUP100_phaseII_D02')\n",
    "chlabels = dataset.get_channel_labels()\n",
    "timeseries1 = dataset.get_time_series_details(chlabels[0])\n",
    "eegfs1= timeseries1.sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "aeaf0329-9cf3-4e57-a066-3d86e4fcd380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#structure split into it's respective fields\n",
    "split = split_HUP203\n",
    "fs = 512;\n",
    "chLabels = np.transpose(split['chLabels'])\n",
    "values = np.transpose(split['values'])\n",
    "seqs = np.transpose(split['sequences'])\n",
    "leaders = np.transpose(split['leaders'])\n",
    "global_coi = np.transpose(split['global_coi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab7617-779f-4b2f-993d-f3aace73dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use % operator to have the same functionality as sprintf (link: https://stackoverflow.com/questions/5309978/sprintf-like-functionality-in-python )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733856e6-d582-4d51-9f85-362777b9d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_mean(ch):\n",
    "    val = np.transpose(split['values'])[ch,0]\n",
    "    return np.mean(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "609d20a1-3a4f-4277-9bc0-efc2c565f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_seqs(I):\n",
    "    if seqs[I,0].size != 0:\n",
    "        X = np.concatenate(np.concatenate(seqs[I,0]))\n",
    "    else:\n",
    "        X = []\n",
    "    return X #recreates the GDF from which the sequence was parsed - I can be used to iterate through the whole code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d596cd8-3b76-4807-bcca-e5494d431d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs2 = [];\n",
    "for I in range(len(seqs)):\n",
    "    print(values[I,0]) #will show you the values half a second both ways from spike for each sequence concatenated\n",
    "    seq_concat = concat_seqs(I)\n",
    "    seqs2.append(seq_concat)\n",
    "    print(len((seq_concat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4a9801c5-c862-412d-a1c7-8acee0fc1500",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j3/ps9_bddj0kg0ds3px8t769_00000gn/T/ipykernel_33274/870685330.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseqs_nonull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/j3/ps9_bddj0kg0ds3px8t769_00000gn/T/ipykernel_33274/870685330.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseqs_nonull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "seqs_nonull = [x for x in seqs2 if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d91d45-b5f9-4eeb-8f52-e1e375f0c688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3473c-ae79-485b-a967-94bdf3f45c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_mean(ch, seq_idx):\n",
    "    val = split_1['values_all'][0][seq_idx][:,ch] \n",
    "    return np.mean(val)\n",
    "\n",
    "def mean_max(sequence_split, values, seq_idx):\n",
    "    seq_0_concat = np.concatenate(sequence_split)\n",
    "    seq_0_concat = np.concatenate(seq_0_concat) #double concatenate so that everything is in a array corresponding - basically turns into GDF\n",
    "    ch_uniq = np.unique(seq_0_concat[:,0]) #finds the unique channels in each run_time\n",
    "    #finds the mean of the max of each channel's spike index.\n",
    "    meanmax_per_ch = [];\n",
    "    all_max = []\n",
    "    for ch in ch_uniq:\n",
    "        x = np.where(seq_0_concat[:,0] == ch)[0] #index where all spikes are per channel per run_time\n",
    "        max_in_ch = []\n",
    "        chs = []\n",
    "        for i in x:\n",
    "            val = values[seq_0_concat[i,1]-20:seq_0_concat[i,1]+20, ch] - (ch, seq_idx) #finding value at the spike and channel from x\n",
    "            val_max = np.max(np.abs(val))\n",
    "            max_in_ch.append(val_max)\n",
    "            chs.append(np.unique(ch))\n",
    "        meanmax_per_ch.append(np.mean(max_in_ch))\n",
    "        all_max.append([np.concatenate(chs),max_in_ch])\n",
    "        \n",
    "    chs2 = (np.concatenate(np.transpose(all_max)[0]))\n",
    "    maxs2 = (np.concatenate(np.transpose(all_max)[1]))\n",
    "    all_max_2 = [chs2,maxs2] #reshape of maxs in all channels.\n",
    "    return meanmax_per_ch, ch_uniq, all_max_2\n",
    "\n",
    "def ALL_mean_max(split_1): #input would be the complete matrix assuming 'values_all' and 'seqs_all' are the base names\n",
    "    mean_max_ALL = []\n",
    "    ch_uniq_ALL = []\n",
    "    max_I_ALL = []\n",
    "    \n",
    "    for I in range(len(split_1['values'][0])):\n",
    "        values_gdf_I = split_1['values'][0,I]\n",
    "        seq_I = split_1['seqs_all'][0,I]\n",
    "        mean_max_seq_I, ch_uniq_I, all_max_I = mean_max(seq_I,values_gdf_I,I)\n",
    "        mean_max_ALL.append(mean_max_seq_I)\n",
    "        ch_uniq_ALL.append(ch_uniq_I)\n",
    "        max_I_ALL.append(all_max_I)\n",
    "    \n",
    "    ch_uniq_AL_C = np.concatenate(ch_uniq_ALL)\n",
    "    mean_max_ALL_C = np.concatenate(mean_max_ALL)\n",
    "    ALL_CH = []\n",
    "    ALL_maxvalues = []\n",
    "    for s in range(len(max_I_ALL)):\n",
    "        ALL_CH.append((max_I_ALL[s][0]))\n",
    "        ALL_maxvalues.append((max_I_ALL[s][1]))\n",
    "    ALL_CH = np.concatenate(ALL_CH)\n",
    "    ALL_maxvalues = np.concatenate(ALL_maxvalues)\n",
    "    max_I_ALL = [ALL_CH,ALL_maxvalues]\n",
    "    ALL_mean_max_with_ch = [ch_uniq_AL_C,mean_max_ALL_C]\n",
    "    return ALL_mean_max_with_ch, max_I_ALL\n",
    "\n",
    "#creates a compilation of every channel in all gdfs and there respective means of max absolute peak values \n",
    "def meanofmeanmax_per_ch(split_1): #input is the complete split file.\n",
    "    all_mean_max, max_I_all = ALL_mean_max(split_1) #uses ALL_mean_max function to get you a complete list of concatenated mean max's\n",
    "\n",
    "    #code to get means of means per channel.\n",
    "    all_mean_max = np.transpose(all_mean_max)\n",
    "    max_I_all = np.transpose(max_I_all)\n",
    "    popmean= np.nanmean(max_I_all[:,1])\n",
    "    popstd = np.nanstd(max_I_all[:,1])\n",
    "    ch_uniq = np.unique(all_mean_max[:,0]) #finds the unique channels in concatenated list\n",
    "    ch_uniq_ALL = np.unique(max_I_all[:,0])\n",
    "    \n",
    "    means = []\n",
    "    means_from_all_maxes = []\n",
    "    std_from_all_maxes = []\n",
    "    for ch in ch_uniq:\n",
    "        x = np.where(all_mean_max[:,0] == ch)[0]#index where all spikes are per channel per run_time\n",
    "        means.append(np.mean(all_mean_max[x,1]))\n",
    "    for ch2 in ch_uniq_ALL:\n",
    "        x2 = np.where(max_I_all[:,0] == ch2)[0]\n",
    "        means_from_all_maxes.append(np.mean(max_I_all[x2,1]))\n",
    "        std_from_all_maxes.append(np.std(max_I_all[x2,1]))\n",
    "    meanofmeanmax = [ch_uniq,means]    \n",
    "    stats_per_ch = [ch_uniq_ALL, means_from_all_maxes, std_from_all_maxes]\n",
    "    \n",
    "    return np.transpose(meanofmeanmax), np.transpose(stats_per_ch), popmean, popstd # ['channel','mean of mean max'] ['channel', 'mean of maxes for all channels', 'std of maxes for all channels']\n",
    "\n",
    "#test for significance\n",
    "from scipy import stats as st\n",
    "\n",
    "#perform 1-sample t test\n",
    "def stu_ttest_per_chn(split_1):\n",
    "    _ , max_I_all = ALL_mean_max(split_1)\n",
    "    _ , stats_ch_ALL, popmean, popstd = meanofmeanmax_per_ch(split_1)\n",
    "    max_I_all = np.transpose(max_I_all)\n",
    "    ch_uniq_ALL = np.unique(max_I_all[:,0])\n",
    "    stats_per_chn = []\n",
    "    for ch2 in ch_uniq_ALL:\n",
    "        x2 = np.where(max_I_all[:,0] == ch2)[0]\n",
    "        stats = st.ttest_1samp(a=max_I_all[x2,1], popmean=popmean,alternative='greater')\n",
    "        stats_per_chn.append(stats)\n",
    "    stats_per_chn_labeled = [ch_uniq_ALL, stats_per_chn];\n",
    "    return np.transpose(stats_per_chn_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad74d73-a65d-4089-837d-1935436cbaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
